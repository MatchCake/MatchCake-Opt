{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# NIF Deep Learning (NIFDL) for Classification Tasks\n",
    "This notebook demonstrates the implementation of a quantum-classical hybrid model called NIF Deep Learning (NIFDL) using the Matchcake library. The model is designed for classification tasks and leverages the Non-Interacting Fermionic Device (NIFD) for quantum computations. The notebook also showcases the use of PyTorch Lightning for training and evaluation, as well as the Ax library for hyperparameter optimization."
   ],
   "id": "c11b257a04e4cb48"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import os\n",
    "import datetime\n",
    "import time\n",
    "from pathlib import Path\n",
    "from typing import Optional, Any\n",
    "import json\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pennylane as qml\n",
    "import torch\n",
    "from ax import RangeParameterConfig\n",
    "from matchcake import NonInteractingFermionicDevice\n",
    "from matchcake.operations import SptmAngleEmbedding, SptmfRxRx, SptmFHH\n",
    "\n",
    "from matchcake_opt.datasets import *\n",
    "from matchcake_opt.modules.classification_model import ClassificationModel\n",
    "from matchcake_opt.tr_pipeline.automl_pipeline import AutoMLPipeline\n",
    "from matchcake_opt.tr_pipeline.lightning_pipeline import LightningPipeline"
   ],
   "id": "3b95af772cefb5b3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "In the following cell we define the NIFDL model class, which inherits from `ClassificationModel`. The model consists of a quantum circuit implemented using PennyLane, and it includes methods for building the model, defining the quantum circuit, and performing forward passes.",
   "id": "e1f9ef65d39494b7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class NIFDL(ClassificationModel):\n",
    "    MODEL_NAME = \"NIFDL\"\n",
    "    DEFAULT_N_QUBITS = 16\n",
    "    DEFAULT_LEARNING_RATE = 2e-4\n",
    "    DEFAULT_N_LAYERS = 6\n",
    "\n",
    "    HP_CONFIGS = [\n",
    "        RangeParameterConfig(\n",
    "            name=\"learning_rate\",\n",
    "            parameter_type=\"float\",\n",
    "            bounds=(1e-5, 0.1),\n",
    "        ),\n",
    "        RangeParameterConfig(\n",
    "            name=\"n_qubits\",\n",
    "            parameter_type=\"int\",\n",
    "            bounds=(4, 32),\n",
    "            step_size=2,\n",
    "        ),\n",
    "        RangeParameterConfig(\n",
    "            name=\"n_layers\",\n",
    "            parameter_type=\"int\",\n",
    "            bounds=(1, 10),\n",
    "        ),\n",
    "    ]\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            input_shape: Optional[tuple[int, ...]],\n",
    "            output_shape: Optional[tuple[int, ...]],\n",
    "            learning_rate: float = DEFAULT_LEARNING_RATE,\n",
    "            n_qubits: int = DEFAULT_N_QUBITS,\n",
    "            n_layers: int = DEFAULT_N_LAYERS,\n",
    "            **kwargs,\n",
    "    ):\n",
    "        super().__init__(input_shape=input_shape, output_shape=output_shape, learning_rate=learning_rate, **kwargs)\n",
    "        self.save_hyperparameters(\"learning_rate\", \"n_qubits\", \"n_layers\")\n",
    "        self.n_qubits = n_qubits\n",
    "        self.n_layers = n_layers\n",
    "        self.n_encoders = 8\n",
    "        self.R_DTYPE = torch.float32\n",
    "        self.C_DTYPE = torch.cfloat\n",
    "        self.q_device = NonInteractingFermionicDevice(\n",
    "            wires=self.n_qubits, r_dtype=self.R_DTYPE, c_dtype=self.C_DTYPE, show_progress=False\n",
    "        )\n",
    "        self.q_node = qml.QNode(self.circuit, self.q_device, interface=\"torch\", diff_method=\"backprop\")\n",
    "        self._weight_shapes = {\"weights\": (self.n_layers, (self.n_qubits - 1) * 2)}\n",
    "        self.flatten = torch.nn.Flatten()\n",
    "        self.encoders = torch.nn.ModuleList(\n",
    "            [\n",
    "                qml.qnn.TorchLayer(self.q_node, self._weight_shapes)\n",
    "                for _ in range(self.n_encoders)\n",
    "            ]\n",
    "        )\n",
    "        self.readout = torch.nn.LazyLinear(self.output_size)\n",
    "        self._build()\n",
    "\n",
    "    def _build(self):\n",
    "        dummy_input = torch.randn((3, *self.input_shape)).to(device=self.device)\n",
    "        with torch.no_grad():\n",
    "            self(dummy_input)\n",
    "        return self\n",
    "\n",
    "    def circuit(self, inputs, weights):\n",
    "        SptmAngleEmbedding(inputs, wires=range(self.n_qubits))\n",
    "        for i in range(self.n_layers):\n",
    "          for j in range(self.n_qubits - 1):\n",
    "            SptmfRxRx(weights[i, j*2 : j*2+2], wires=[j, j+1])\n",
    "            SptmFHH(wires=[j, j+1])\n",
    "        return [qml.expval(qml.PauliZ(wires=i)) for i in range(self.n_qubits)]\n",
    "\n",
    "    def forward(self, x) -> Any:\n",
    "        x = self.flatten(x).to(self.device)\n",
    "        x_split = torch.split(x, self.n_qubits, dim=1)\n",
    "        x_out = [layer(x_chunk) for layer, x_chunk in zip(self.encoders, x_split)]\n",
    "        x = torch.cat(x_out, dim=1).to(self.device)\n",
    "        x = self.readout(x)\n",
    "        return x\n",
    "\n",
    "    @property\n",
    "    def input_size(self):\n",
    "        return int(np.prod(self.input_shape))\n",
    "\n",
    "    @property\n",
    "    def output_size(self):\n",
    "        return int(np.prod(self.output_shape))"
   ],
   "id": "586f30eed53a5ae",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Dataset\n",
    "dataset_name = \"Digits2D\"\n",
    "fold_id = 0\n",
    "batch_size = 32\n",
    "random_state = 0\n",
    "num_workers = 0\n",
    "\n",
    "# Model\n",
    "model_cls = NIFDL\n",
    "\n",
    "# Pipeline\n",
    "job_output_folder = Path(os.getcwd()) / \"data\" / \"automl\" / dataset_name / model_cls.MODEL_NAME\n",
    "checkpoint_folder = Path(job_output_folder) / \"checkpoints\"\n",
    "pipeline_args = dict(\n",
    "    max_epochs=128,  # increase at least to 256\n",
    "    max_time=\"00:00:02:00\",  # DD:HH:MM:SS, increase at least to \"00:01:00:00\"\n",
    ")"
   ],
   "id": "412328c44c55e453",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Then, we set up the data module using the specified dataset and parameters.",
   "id": "3847ed18ac6e57fd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "datamodule = DataModule.from_dataset_name(\n",
    "    dataset_name,\n",
    "    fold_id=fold_id,\n",
    "    batch_size=batch_size,\n",
    "    random_state=random_state,\n",
    "    num_workers=num_workers,\n",
    ")"
   ],
   "id": "42cb94221bd39753",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Lightning Pipeline - Model Training and Evaluation\n",
    "In this section, we create a Lightning Pipeline for training and evaluating the NIFDL model."
   ],
   "id": "d13cf82e118d84eb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "model_args = dict(\n",
    "    n_qubits=16,\n",
    "    learning_rate=2e-4,\n",
    "    n_layers=6,\n",
    ")\n",
    "lightning_pipeline = LightningPipeline(\n",
    "    model_cls=model_cls,\n",
    "    datamodule=datamodule,\n",
    "    checkpoint_folder=checkpoint_folder,\n",
    "    max_epochs=10,\n",
    "    max_time=\"00:00:03:00\",  # DD:HH:MM:SS\n",
    "    overwrite_fit=True,\n",
    "    verbose=True,\n",
    "    **model_args,\n",
    ")"
   ],
   "id": "8832b1d06113ac48"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "start_time = time.perf_counter()\n",
    "metrics = lightning_pipeline.run()\n",
    "end_time = time.perf_counter()\n",
    "elapsed_time = datetime.timedelta(seconds=end_time - start_time)\n",
    "print(f\"Time taken: {elapsed_time}\")\n",
    "print(\"⚡\" * 20, \"\\nValidation Metrics:\\n\", metrics, \"\\n\", \"⚡\" * 20)\n",
    "test_metrics = lightning_pipeline.run_test()\n",
    "print(\"⚡\" * 20, \"\\nTest Metrics:\\n\", test_metrics, \"\\n\", \"⚡\" * 20)"
   ],
   "id": "7d8a499f05426a0d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# AutoML Pipeline - Hyperparameter Optimization",
   "id": "688b66fca9889c36"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "automl_pipeline = AutoMLPipeline(\n",
    "    model_cls=model_cls,\n",
    "    datamodule=datamodule,\n",
    "    checkpoint_folder=checkpoint_folder,\n",
    "    automl_iterations=5,  # increase at least to 32\n",
    "    inner_max_epochs=10,  # increase at least to 128\n",
    "    inner_max_time=\"00:00:01:00\",  # increase at least to \"00:00:10:00\"\n",
    "    automl_overwrite_fit=True,\n",
    "    **pipeline_args\n",
    ")"
   ],
   "id": "16001dd8071bc8b0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "start_time = time.perf_counter()\n",
    "automl_pipeline.run()\n",
    "end_time = time.perf_counter()\n",
    "print(f\"Time taken: {end_time - start_time:.4f} seconds\")"
   ],
   "id": "8c84ee5352220970",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "print(f\"Best Hyperparameters:\\n{json.dumps(automl_pipeline.get_best_params(), indent=2, default=str)}\")",
   "id": "9e966f925f2b5ad3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "lt_pipeline, metrics = automl_pipeline.run_best_pipeline()\n",
    "print(\"⚡\" * 20, \"\\nValidation Metrics:\\n\", metrics, \"\\n\", \"⚡\" * 20)"
   ],
   "id": "3e536e4ced33a442",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "test_metrics = lt_pipeline.run_test()\n",
    "print(\"⚡\" * 20, \"\\nTest Metrics:\\n\", test_metrics, \"\\n\", \"⚡\" * 20)"
   ],
   "id": "4bdef94d9cfb1944",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "-------------------------------------------------------",
   "id": "c2551cd1690867ec"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

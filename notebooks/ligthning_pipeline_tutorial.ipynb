{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "\n",
    "import datetime\n",
    "import os\n",
    "import time\n",
    "from pathlib import Path\n",
    "from typing import Optional\n",
    "\n",
    "import numpy as np\n",
    "import pennylane as qml\n",
    "import torch\n",
    "from ax import ChoiceParameterConfig, RangeParameterConfig\n",
    "from matchcake import NonInteractingFermionicDevice\n",
    "from matchcake.operations import (\n",
    "    SingleParticleTransitionMatrixOperation,\n",
    ")\n",
    "from torchvision.transforms import Resize\n",
    "\n",
    "from bolightningpipeline.datasets import *\n",
    "from bolightningpipeline.modules.classification_model import ClassificationModel\n",
    "from bolightningpipeline.tr_pipeline.lightning_pipeline import LightningPipeline"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class NIFCNN(ClassificationModel):\n",
    "    MODEL_NAME = \"NIFCNN\"\n",
    "    DEFAULT_N_QUBITS = 16\n",
    "    DEFAULT_LEARNING_RATE = 2e-4\n",
    "    DEFAULT_ENCODER_OUTPUT_ACTIVATION = \"Tanh\"\n",
    "    MIN_INPUT_SIZE = (28, 28)\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            input_shape: Optional[tuple[int, ...]],\n",
    "            output_shape: Optional[tuple[int, ...]],\n",
    "            learning_rate: float = DEFAULT_LEARNING_RATE,\n",
    "            n_qubits: int = DEFAULT_N_QUBITS,\n",
    "            encoder_output_activation: str = DEFAULT_ENCODER_OUTPUT_ACTIVATION,\n",
    "            **kwargs,\n",
    "    ):\n",
    "        super().__init__(input_shape=input_shape, output_shape=output_shape, learning_rate=learning_rate, **kwargs)\n",
    "        self.save_hyperparameters(\"learning_rate\", \"n_qubits\", \"encoder_output_activation\")\n",
    "        self.n_qubits = n_qubits\n",
    "        self.R_DTYPE = torch.float32\n",
    "        self.C_DTYPE = torch.cfloat\n",
    "        self._n_params = np.triu_indices(2 * self.n_qubits, k=1)[0].size\n",
    "        self.q_device = NonInteractingFermionicDevice(\n",
    "            wires=self.n_qubits, r_dtype=self.R_DTYPE, c_dtype=self.C_DTYPE, show_progress=False\n",
    "        )\n",
    "        self.encoder_output_activation = encoder_output_activation\n",
    "        self.input_resize = Resize(self.MIN_INPUT_SIZE)\n",
    "        self.local_fields_encoder = torch.nn.Sequential(\n",
    "            torch.nn.LazyConv2d(512, kernel_size=7),\n",
    "            torch.nn.LazyBatchNorm2d(),\n",
    "            torch.nn.LazyConv2d(128, kernel_size=5),\n",
    "            torch.nn.LazyBatchNorm2d(),\n",
    "            torch.nn.LazyConv2d(64, kernel_size=3),\n",
    "            torch.nn.LazyBatchNorm2d(),\n",
    "        )\n",
    "\n",
    "        self.local_fields_head = torch.nn.Sequential(\n",
    "            torch.nn.Flatten(),\n",
    "            torch.nn.LazyLinear(self.n_qubits),\n",
    "            getattr(torch.nn, encoder_output_activation)()\n",
    "        )\n",
    "        self._hamiltonian_n_params = np.triu_indices(self.n_qubits, k=1)[0].size\n",
    "        self.zz_body_couplings_head = torch.nn.Sequential(\n",
    "            torch.nn.Flatten(),\n",
    "            torch.nn.LazyLinear(self._hamiltonian_n_params),\n",
    "            getattr(torch.nn, encoder_output_activation)()\n",
    "        )\n",
    "        self.xx_body_couplings_head = torch.nn.Sequential(\n",
    "            torch.nn.Flatten(),\n",
    "            torch.nn.LazyLinear(self._hamiltonian_n_params),\n",
    "            getattr(torch.nn, encoder_output_activation)()\n",
    "        )\n",
    "\n",
    "        self.zz_body_coupling_weights = torch.nn.Parameter(torch.randn(self._hamiltonian_n_params), requires_grad=True)\n",
    "        self.xx_body_coupling_weights = torch.nn.Parameter(torch.randn(self._hamiltonian_n_params), requires_grad=True)\n",
    "\n",
    "        self.local_fields_op_eigvals = torch.nn.Parameter(torch.from_numpy(np.array([1.0, -1.0])).float(),\n",
    "                                                          requires_grad=False)  # eigvals(Z)\n",
    "        self.zz_eigvals = torch.nn.Parameter(torch.from_numpy(np.array([1.0, -1.0, -1.0, 1.0])).float(),\n",
    "                                             requires_grad=False)  # eigvals(ZZ)\n",
    "        self.xx_eigvals = torch.nn.Parameter(torch.from_numpy(np.array([1.0, -1.0, 1.0, -1.0])).float(),\n",
    "                                             requires_grad=False)  # eigvals(XX)\n",
    "\n",
    "        self.local_fields_wires = [[i] for i in range(self.n_qubits)]\n",
    "        self.couplings_wires = [[i, j] for i, j in np.vstack(np.triu_indices(self.n_qubits, k=1)).T]\n",
    "\n",
    "        self.weights = torch.nn.Parameter(torch.rand((int(self.output_size), self._n_params)), requires_grad=True)\n",
    "        torch.nn.init.xavier_uniform_(self.weights)\n",
    "        self._build()\n",
    "\n",
    "    def _build(self):\n",
    "        dummy_input = torch.randn((3, *self.input_shape)).to(device=self.device)\n",
    "        with torch.no_grad():\n",
    "            self(dummy_input)\n",
    "        return self\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.preprocess_input(x)\n",
    "        embeddings = self.local_fields_encoder(x)\n",
    "\n",
    "        local_fields = self.local_fields_head(embeddings)\n",
    "        zz_couplings = self.zz_body_couplings_head(embeddings)\n",
    "        xx_couplings = self.xx_body_couplings_head(embeddings)\n",
    "        self.q_device.execute_generator(self.circuit_gen(), reset=True)\n",
    "\n",
    "        local_fields_probs = (\n",
    "            self.q_device.probability(wires=self.local_fields_wires)\n",
    "            .to(dtype=self.q_device.R_DTYPE, device=self.torch_device)\n",
    "        )\n",
    "        couplings_probs = (\n",
    "            self.q_device.probability(wires=self.couplings_wires)\n",
    "            .to(dtype=self.q_device.R_DTYPE, device=self.torch_device)\n",
    "        )\n",
    "        weighted_local_eigvals = torch.einsum(\n",
    "            \"bi,kij,j->bk\", local_fields, local_fields_probs, self.local_fields_op_eigvals\n",
    "        )\n",
    "        weighted_zz_eigvals = torch.einsum(\n",
    "            \"bi,kij,j->bk\", zz_couplings, couplings_probs, self.zz_eigvals\n",
    "        )\n",
    "        weighted_xx_eigvals = torch.einsum(\n",
    "            \"bi,kij,j->bk\", xx_couplings, couplings_probs, self.xx_eigvals\n",
    "        )\n",
    "\n",
    "        expval = weighted_local_eigvals + weighted_zz_eigvals + weighted_xx_eigvals\n",
    "        return expval\n",
    "\n",
    "    def circuit_gen(self):\n",
    "        yield qml.BasisState(self.initial_basis_state, wires=self.wires)\n",
    "        yield self.get_sptm_weights()\n",
    "        return\n",
    "\n",
    "    def get_sptm_weights(self):\n",
    "        \"\"\"\n",
    "        Compute the single-particle transition matrix (SPTM) weights based on the initialized weight tensor.\n",
    "\n",
    "        This method constructs a tensor, `h`, which encodes the pairwise weight interactions\n",
    "        in a prescribed upper triangular form. It then symmetrizes `h` to ensure anti-symmetry\n",
    "        about the main diagonal. Afterward, the matrix exponential of `h` is computed to generate\n",
    "        the SPTM. Finally, the SPTM is encapsulated in a `SingleParticleTransitionMatrixOperation`\n",
    "        object for further usage.\n",
    "\n",
    "        :return: An instance of `SingleParticleTransitionMatrixOperation` that encapsulates\n",
    "            the computed single-particle transition matrix based on the initialized weights.\n",
    "            The shape of the SPTM is (n_classes, 2 * n_qubits, 2 * n_qubits).\n",
    "        :rtype: SingleParticleTransitionMatrixOperation\n",
    "        \"\"\"\n",
    "        h = torch.zeros(\n",
    "            (int(self.output_size), 2 * self.n_qubits, 2 * self.n_qubits), dtype=self.R_DTYPE, device=self.torch_device\n",
    "        )\n",
    "        triu_indices = np.triu_indices(2 * self.n_qubits, k=1)\n",
    "        h[:, triu_indices[0], triu_indices[1]] = self.weights\n",
    "        h = h - h.mT\n",
    "        sptm = torch.matrix_exp(h)\n",
    "        return SingleParticleTransitionMatrixOperation(sptm, wires=self.wires)\n",
    "\n",
    "    def preprocess_input(self, x: torch.Tensor, **kwargs) -> torch.Tensor:\n",
    "        x = x.reshape(x.shape[0], -1, x.shape[-2], x.shape[-1])\n",
    "        if x.shape[-2] < self.MIN_INPUT_SIZE[-2] or x.shape[-1] < self.MIN_INPUT_SIZE[-1]:\n",
    "            x = self.input_resize(x)\n",
    "        return x\n",
    "\n",
    "    @property\n",
    "    def torch_device(self):\n",
    "        return self.device\n",
    "\n",
    "    @property\n",
    "    def wires(self):\n",
    "        return self.q_device.wires\n",
    "\n",
    "    @property\n",
    "    def initial_basis_state(self):\n",
    "        return np.zeros(self.n_qubits, dtype=int)\n",
    "\n",
    "    @property\n",
    "    def output_size(self):\n",
    "        return int(np.prod(self.output_shape))\n"
   ],
   "id": "773fa29d353f3b44",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "dataset_name = \"Digits2D\"\n",
    "fold_id = 0\n",
    "batch_size = 32\n",
    "random_state = 0\n",
    "num_workers = 0\n",
    "model_cls = NIFCNN\n",
    "model_args = dict(\n",
    "    n_qubits=16,\n",
    "    learning_rate=2e-4,\n",
    "    encoder_output_activation=\"Tanh\",\n",
    ")\n",
    "job_output_folder_root = Path(os.getcwd()) / \"data\" / \"lightning\"\n",
    "job_output_folder = Path(dataset_name) / model_cls.MODEL_NAME\n",
    "\n",
    "checkpoint_folder = Path(job_output_folder) / \"checkpoints\""
   ],
   "id": "7650c0c97d2d27a8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "datamodule = DataModule.from_dataset_name(\n",
    "    dataset_name,\n",
    "    fold_id=fold_id,\n",
    "    batch_size=batch_size,\n",
    "    random_state=random_state,\n",
    "    num_workers=num_workers,\n",
    ")\n",
    "lightning_pipeline = LightningPipeline(\n",
    "    model_cls=model_cls,\n",
    "    datamodule=datamodule,\n",
    "    checkpoint_folder=checkpoint_folder,\n",
    "    max_epochs=10,\n",
    "    max_time=\"00:00:03:00\",  # DD:HH:MM:SS\n",
    "    overwrite_fit=True,\n",
    "    verbose=True,\n",
    "    **model_args,\n",
    ")"
   ],
   "id": "194d37919aea6ac0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "start_time = time.perf_counter()\n",
    "metrics = lightning_pipeline.run()\n",
    "print(\"⚡\" * 20, \"\\nValidation Metrics:\\n\", metrics, \"\\n\", \"⚡\" * 20)\n",
    "test_metrics = lightning_pipeline.run_test()\n",
    "print(\"⚡\" * 20, \"\\nTest Metrics:\\n\", test_metrics, \"\\n\", \"⚡\" * 20)\n",
    "end_time = time.perf_counter()\n",
    "elapsed_time = datetime.timedelta(seconds=end_time - start_time)\n",
    "print(f\"Time taken: {elapsed_time}\")"
   ],
   "id": "7d2a933b5d774a43",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
